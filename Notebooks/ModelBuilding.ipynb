{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building / selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at building/selecting our models, as we have a classifcation task (predicting 0 or 1) we will compare a verity of classifcation algorithms like\n",
    "* Random Forest\n",
    "* Gradient boosting machines\n",
    "* Adaboost \n",
    "* Logistic regression\n",
    "\n",
    "and so on.\n",
    "\n",
    "As we are interested in roc_auc scores we will predict probabilities from our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR = \"../Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_DIR + \"processed_train.csv\")\n",
    "test_data = pd.read_csv(DATA_DIR + \"processed_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a function for easily testing different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(train_data : pd.DataFrame,  \n",
    "                         model, \n",
    "                         print : bool= True,\n",
    "                         **model_paramaters):\n",
    "    '''\n",
    "    Function for fitting data to a model using stratified k fold with 10 folds.\n",
    "    Args:\n",
    "    train_data (pd.DataFrame)\n",
    "    test_data (pd.DataFrame)\n",
    "    model (sklearn style model)\n",
    "    model_paramaters (dictionary)\n",
    "    '''\n",
    "    X_train = train_data.drop(\"loan_status\", axis = 1)\n",
    "   \n",
    "    y_train = train_data[\"loan_status\"]\n",
    "\n",
    "\n",
    "    model.set_params(**model_paramaters)\n",
    "\n",
    "    strat_k_fold = StratifiedKFold(10, shuffle= True)\n",
    "    train_auc_scores = []\n",
    "    val_auc_scores = []\n",
    "\n",
    "    for fold , (train_ind, val_inx) in enumerate(strat_k_fold.split(X_train, y_train), 1):\n",
    "        x_train_fold, x_val_fold = X_train.iloc[train_ind], X_train.iloc[val_inx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_ind], y_train.iloc[val_inx]\n",
    "\n",
    "        model.fit(x_train_fold, y_train_fold)\n",
    "\n",
    "        y_train_pred = model.predict_proba(x_train_fold)[:, 1]\n",
    "        train_auc = roc_auc_score(y_train_fold, y_train_pred)\n",
    "        train_auc_scores.append(train_auc)\n",
    "\n",
    "        y_val_pred = model.predict_proba(x_val_fold)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        val_auc_scores.append(val_auc)\n",
    "        if print:\n",
    "            print(f\"Fold {fold}: Train AUC = {train_auc:.4f}, Validation AUC = {val_auc:.4f}\")\n",
    "    mean_train_auc = np.mean(train_auc_scores)\n",
    "    mean_val_auc = np.mean(val_auc_scores)\n",
    "    if print:\n",
    "        print(f\"\\nMean Train AUC: {mean_train_auc:.4f}\")\n",
    "        print(f\"Mean Validation AUC: {mean_val_auc:.4f}\")\n",
    "    return mean_val_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our model using 10 stratified Kfolds on our training data, using the mean validation ROC AUC as our model comparison criteria. First we will just test our models with no hyperparamaters tuning to see which one does the best oob, and hyperparamater tune that model from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [xgb.XGBClassifier(),\n",
    "          RandomForestClassifier(),\n",
    "          KNeighborsClassifier(5),\n",
    "          GradientBoostingClassifier(),\n",
    "          AdaBoostClassifier(),\n",
    "          LogisticRegression(),\n",
    "          BaggingClassifier()\n",
    " ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_names = []\n",
    "model_val_roc = []\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    val_roc_auc = train_and_test_model(train_data, model, print = False)\n",
    "\n",
    "    model_names.append(type(model).__name__)\n",
    "    model_val_roc.append(val_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>VAL_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.952658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.939588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.934766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.921986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.911697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.840676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.732367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model   VAL_ROC\n",
       "0               XGBClassifier  0.952658\n",
       "3  GradientBoostingClassifier  0.939588\n",
       "1      RandomForestClassifier  0.934766\n",
       "4          AdaBoostClassifier  0.921986\n",
       "6           BaggingClassifier  0.911697\n",
       "5          LogisticRegression  0.840676\n",
       "2        KNeighborsClassifier  0.732367"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred = pd.DataFrame({\"Model\" : model_names, \"VAL_ROC\" :model_val_roc} )\n",
    "model_pred.sort_values(by=\"VAL_ROC\", ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our XGBclassifer does significantly better OOB then the others do. So we will now tune XGBclassifier from here to achieve the highest auc roc possible.\n",
    "\n",
    "To do so we will make use of optuna optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-15 11:31:43,106] A new study created in memory with name: no-name-7bafef55-570d-457b-8f2b-9fbd5ee361c5\n",
      "[I 2024-10-15 11:31:45,766] Trial 0 finished with value: 0.9522063704801743 and parameters: {'eta': 0.0004618504768450964, 'alpha': 1.4392104489452895, 'num_leaves': 20, 'learning_rate': 0.006901748808690155, 'max_depth': 11, 'n_estimators': 500}. Best is trial 0 with value: 0.9522063704801743.\n",
      "[I 2024-10-15 11:31:48,352] Trial 1 finished with value: 0.9521088975805899 and parameters: {'eta': 0.00039400641054660596, 'alpha': 0.07242828146600491, 'num_leaves': 70, 'learning_rate': 0.0004364648913994702, 'max_depth': 7, 'n_estimators': 500}. Best is trial 0 with value: 0.9522063704801743.\n",
      "[I 2024-10-15 11:31:51,026] Trial 2 finished with value: 0.9524314523578153 and parameters: {'eta': 0.20955332879722616, 'alpha': 0.3572700235694673, 'num_leaves': 40, 'learning_rate': 0.9304422534888797, 'max_depth': 7, 'n_estimators': 100}. Best is trial 2 with value: 0.9524314523578153.\n",
      "[I 2024-10-15 11:31:53,633] Trial 3 finished with value: 0.952787749449403 and parameters: {'eta': 0.013162160042491215, 'alpha': 0.001682653286215144, 'num_leaves': 30, 'learning_rate': 0.00243456777346209, 'max_depth': 5, 'n_estimators': 100}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:31:56,028] Trial 4 finished with value: 0.9522743099037381 and parameters: {'eta': 0.003962694637028476, 'alpha': 0.018341189327206395, 'num_leaves': 50, 'learning_rate': 0.031073032717179427, 'max_depth': 11, 'n_estimators': 500}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:31:58,538] Trial 5 finished with value: 0.9523405187472924 and parameters: {'eta': 0.002989544912705267, 'alpha': 0.014371014329846844, 'num_leaves': 10, 'learning_rate': 0.007626214468265758, 'max_depth': 5, 'n_estimators': 1000}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:00,930] Trial 6 finished with value: 0.9527315661661262 and parameters: {'eta': 0.0005119368666371818, 'alpha': 0.07484087629841996, 'num_leaves': 30, 'learning_rate': 0.1434963571620552, 'max_depth': 13, 'n_estimators': 1000}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:03,389] Trial 7 finished with value: 0.9518819594083509 and parameters: {'eta': 0.00254179192625773, 'alpha': 0.0011931260295348983, 'num_leaves': 70, 'learning_rate': 0.08780572536011018, 'max_depth': 11, 'n_estimators': 50}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:05,772] Trial 8 finished with value: 0.9527051353858909 and parameters: {'eta': 0.00550563638237773, 'alpha': 0.05141569558748085, 'num_leaves': 50, 'learning_rate': 0.030882280026963034, 'max_depth': 9, 'n_estimators': 1000}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:08,144] Trial 9 finished with value: 0.952335214418768 and parameters: {'eta': 0.026519530931274845, 'alpha': 1.045844358463176, 'num_leaves': 100, 'learning_rate': 0.10615807461761442, 'max_depth': 9, 'n_estimators': 1000}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:10,822] Trial 10 finished with value: 0.9509776639238323 and parameters: {'eta': 0.06056075525191798, 'alpha': 0.0010466622994048577, 'num_leaves': 30, 'learning_rate': 0.00044373263046714086, 'max_depth': 5, 'n_estimators': 100}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:13,371] Trial 11 finished with value: 0.9524374089714662 and parameters: {'eta': 0.00011288915500166231, 'alpha': 6.1098732535057305, 'num_leaves': 30, 'learning_rate': 0.0020401491194170164, 'max_depth': 13, 'n_estimators': 20}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:15,878] Trial 12 finished with value: 0.951833262822111 and parameters: {'eta': 0.9520206392590082, 'alpha': 0.004069805374206591, 'num_leaves': 30, 'learning_rate': 0.5389816029982393, 'max_depth': 13, 'n_estimators': 10}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:18,503] Trial 13 finished with value: 0.9524445748379236 and parameters: {'eta': 0.019978278515140783, 'alpha': 0.008368559609273548, 'num_leaves': 30, 'learning_rate': 0.00012691795102240519, 'max_depth': 13, 'n_estimators': 100}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:20,896] Trial 14 finished with value: 0.9518403502586867 and parameters: {'eta': 0.000897343275303655, 'alpha': 0.13595249271931872, 'num_leaves': 30, 'learning_rate': 0.002083726305244301, 'max_depth': 5, 'n_estimators': 10}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:23,319] Trial 15 finished with value: 0.9520460765471718 and parameters: {'eta': 0.00010150668575582615, 'alpha': 0.0035184356123115733, 'num_leaves': 10, 'learning_rate': 0.23042313757906496, 'max_depth': 13, 'n_estimators': 20}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:25,665] Trial 16 finished with value: 0.9525752730897736 and parameters: {'eta': 0.0844627254589058, 'alpha': 0.36371456555430187, 'num_leaves': 20, 'learning_rate': 0.0022788411037905215, 'max_depth': 5, 'n_estimators': 50}. Best is trial 3 with value: 0.952787749449403.\n",
      "[I 2024-10-15 11:32:28,052] Trial 17 finished with value: 0.9530410889232069 and parameters: {'eta': 0.0011885751532227777, 'alpha': 8.944219368664037, 'num_leaves': 100, 'learning_rate': 0.025030817306731637, 'max_depth': 5, 'n_estimators': 100}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:30,698] Trial 18 finished with value: 0.9522281224771847 and parameters: {'eta': 0.012475240153276088, 'alpha': 7.123744905282751, 'num_leaves': 100, 'learning_rate': 0.023520850533095373, 'max_depth': 5, 'n_estimators': 100}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:33,551] Trial 19 finished with value: 0.9517692529979136 and parameters: {'eta': 0.0012031573911153166, 'alpha': 2.3160021048105714, 'num_leaves': 100, 'learning_rate': 0.004463868286979357, 'max_depth': 5, 'n_estimators': 100}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:36,330] Trial 20 finished with value: 0.9522716834306358 and parameters: {'eta': 0.007809960880584272, 'alpha': 0.6942937887143851, 'num_leaves': 40, 'learning_rate': 0.0008012015983649206, 'max_depth': 5, 'n_estimators': 100}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:38,970] Trial 21 finished with value: 0.9517711104974133 and parameters: {'eta': 0.00027867413224194685, 'alpha': 0.20083288710966352, 'num_leaves': 100, 'learning_rate': 0.016748532052275385, 'max_depth': 13, 'n_estimators': 1000}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:41,643] Trial 22 finished with value: 0.9521157244719239 and parameters: {'eta': 0.0012621307008852075, 'alpha': 0.035253646223825506, 'num_leaves': 30, 'learning_rate': 0.09700852302436921, 'max_depth': 5, 'n_estimators': 100}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:44,092] Trial 23 finished with value: 0.952564940272409 and parameters: {'eta': 0.0008718376209276825, 'alpha': 2.4321953569326262, 'num_leaves': 30, 'learning_rate': 0.05839544320850369, 'max_depth': 9, 'n_estimators': 1000}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:46,598] Trial 24 finished with value: 0.9521442369509993 and parameters: {'eta': 0.002114203151034162, 'alpha': 0.026054169697926823, 'num_leaves': 100, 'learning_rate': 0.24405399741064243, 'max_depth': 7, 'n_estimators': 100}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:49,333] Trial 25 finished with value: 0.9521274323545879 and parameters: {'eta': 0.00022579362669323134, 'alpha': 0.002958273959010925, 'num_leaves': 30, 'learning_rate': 0.013637630212909702, 'max_depth': 13, 'n_estimators': 20}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:51,964] Trial 26 finished with value: 0.9528907897106746 and parameters: {'eta': 0.014838709655987816, 'alpha': 0.00667299100341198, 'num_leaves': 20, 'learning_rate': 0.31178361493681495, 'max_depth': 5, 'n_estimators': 10}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:54,414] Trial 27 finished with value: 0.952180039458241 and parameters: {'eta': 0.04365995597045299, 'alpha': 0.006891239429297859, 'num_leaves': 20, 'learning_rate': 0.003553210496675109, 'max_depth': 5, 'n_estimators': 10}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:56,894] Trial 28 finished with value: 0.9515820148568002 and parameters: {'eta': 0.15710488329490482, 'alpha': 0.002063365492481272, 'num_leaves': 20, 'learning_rate': 0.46394384665139915, 'max_depth': 5, 'n_estimators': 10}. Best is trial 17 with value: 0.9530410889232069.\n",
      "[I 2024-10-15 11:32:59,373] Trial 29 finished with value: 0.9518122572464428 and parameters: {'eta': 0.018522971354664228, 'alpha': 0.007812992703117218, 'num_leaves': 20, 'learning_rate': 0.0011819216359913894, 'max_depth': 5, 'n_estimators': 10}. Best is trial 17 with value: 0.9530410889232069.\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    xgboost_params = {\n",
    "        \"objective\" : \"binary:logistic\",\n",
    "        \"eval_metric\" : \"auc\",\n",
    "        \"device\" : \"cuda\",\n",
    "        \"eta\" : trial.suggest_loguniform(\"eta\", 1e-4, 1 ),\n",
    "        \"alpha\" : trial.suggest_loguniform(\"alpha\", 1e-3, 10),\n",
    "        \"num_leaves\" : trial.suggest_categorical(\"num_leaves\", [10,20,30,40,50,70, 100]),\n",
    "        \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-4, 1),\n",
    "        \"max_depth\" : trial.suggest_categorical(\"max_depth\", [5,7,9,11,13]),\n",
    "        \"n_estimators\" : trial.suggest_categorical(\"n_estimators\" , [10, 20, 50, 100, 500, 1000])\n",
    "    }\n",
    "    model = xgb.XGBClassifier()\n",
    "    auc = train_and_test_model(train_data, model, print = False, model_paramaters= xgboost_params)\n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials = 30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train our model with the best paramaters on the whole training data before getting our submission file ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value\n",
    "\n",
    "\n",
    "best_model = xgb.XGBClassifier(**study.best_params)\n",
    "best_model.fit(X = train_data.drop(\"loan_status\", axis = 1), y = train_data[\"loan_status\"])\n",
    "test_predictions = best_model.predict_proba(test_data.drop(\"id\", axis = 1))[:, 1]\n",
    "test_predictions_df = pd.DataFrame({\"id\": test_data[\"id\"], \"loan_status\" : test_predictions})\n",
    "test_predictions_df.to_csv(\"../Data/sample_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above submission on kaggle got a public score of 0.93248, we can definatly do better then that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-15 11:53:14,659] A new study created in memory with name: no-name-a2a7ddd8-42ec-4d1c-9ba5-eece0959107c\n",
      "[I 2024-10-15 11:53:17,455] Trial 0 finished with value: 0.9523225184597303 and parameters: {'eta': 0.28877283516086444, 'alpha': 9.867500606929504, 'num_leaves': 70, 'learning_rate': 0.0012986351281651229, 'max_depth': 5, 'n_estimators': 1000, 'weights': 68.06732897247275}. Best is trial 0 with value: 0.9523225184597303.\n",
      "[I 2024-10-15 11:53:20,244] Trial 1 finished with value: 0.9525493411910044 and parameters: {'eta': 0.0005893223338327801, 'alpha': 6.430164222042314, 'num_leaves': 10, 'learning_rate': 0.5890891879706068, 'max_depth': 7, 'n_estimators': 20, 'weights': 24.13973555072063}. Best is trial 1 with value: 0.9525493411910044.\n",
      "[I 2024-10-15 11:53:23,189] Trial 2 finished with value: 0.9524872896614406 and parameters: {'eta': 0.001452760636179762, 'alpha': 0.9767012298076453, 'num_leaves': 100, 'learning_rate': 0.0009857325847804957, 'max_depth': 13, 'n_estimators': 20, 'weights': 8.148948201335315}. Best is trial 1 with value: 0.9525493411910044.\n",
      "[I 2024-10-15 11:53:25,878] Trial 3 finished with value: 0.9525125116907146 and parameters: {'eta': 0.010775873334776191, 'alpha': 3.162036905924321, 'num_leaves': 40, 'learning_rate': 0.7204510433886698, 'max_depth': 7, 'n_estimators': 100, 'weights': 97.59761557899706}. Best is trial 1 with value: 0.9525493411910044.\n",
      "[I 2024-10-15 11:53:28,673] Trial 4 finished with value: 0.9528262055790988 and parameters: {'eta': 0.0005186342494519181, 'alpha': 0.018498970513413846, 'num_leaves': 40, 'learning_rate': 0.00025900810482843263, 'max_depth': 5, 'n_estimators': 500, 'weights': 45.61991765044379}. Best is trial 4 with value: 0.9528262055790988.\n",
      "[I 2024-10-15 11:53:31,875] Trial 5 finished with value: 0.9526401907329888 and parameters: {'eta': 0.0003064379504135558, 'alpha': 0.4233074594835899, 'num_leaves': 20, 'learning_rate': 0.0005779364916121653, 'max_depth': 5, 'n_estimators': 500, 'weights': 54.299235580513816}. Best is trial 4 with value: 0.9528262055790988.\n",
      "[I 2024-10-15 11:53:34,942] Trial 6 finished with value: 0.952679934448318 and parameters: {'eta': 0.00010963773404898718, 'alpha': 0.004864571137914934, 'num_leaves': 30, 'learning_rate': 0.0008525209988854808, 'max_depth': 7, 'n_estimators': 20, 'weights': 11.23434557241042}. Best is trial 4 with value: 0.9528262055790988.\n",
      "[I 2024-10-15 11:53:37,824] Trial 7 finished with value: 0.9530344634256631 and parameters: {'eta': 0.0009163917262693677, 'alpha': 0.7056638513411703, 'num_leaves': 70, 'learning_rate': 0.0005534022810800663, 'max_depth': 7, 'n_estimators': 50, 'weights': 18.64561545460065}. Best is trial 7 with value: 0.9530344634256631.\n",
      "[I 2024-10-15 11:53:40,682] Trial 8 finished with value: 0.9523584739516389 and parameters: {'eta': 0.5434279226258235, 'alpha': 0.003010604776159493, 'num_leaves': 70, 'learning_rate': 0.00026734900322517816, 'max_depth': 7, 'n_estimators': 10, 'weights': 36.90147873106772}. Best is trial 7 with value: 0.9530344634256631.\n",
      "[I 2024-10-15 11:53:43,504] Trial 9 finished with value: 0.9525163592005168 and parameters: {'eta': 0.346647849550498, 'alpha': 0.22134932150178957, 'num_leaves': 40, 'learning_rate': 0.39627007301123707, 'max_depth': 9, 'n_estimators': 50, 'weights': 11.290023411089889}. Best is trial 7 with value: 0.9530344634256631.\n",
      "[I 2024-10-15 11:53:46,071] Trial 10 finished with value: 0.952294398894668 and parameters: {'eta': 0.00901007345967434, 'alpha': 0.047805909801814095, 'num_leaves': 50, 'learning_rate': 0.009425040699944424, 'max_depth': 11, 'n_estimators': 50, 'weights': 77.45940864605629}. Best is trial 7 with value: 0.9530344634256631.\n",
      "[I 2024-10-15 11:53:48,668] Trial 11 finished with value: 0.9526643910954018 and parameters: {'eta': 0.002069653585973693, 'alpha': 0.03831831118869369, 'num_leaves': 70, 'learning_rate': 0.00011213774037442098, 'max_depth': 5, 'n_estimators': 500, 'weights': 40.80330894363656}. Best is trial 7 with value: 0.9530344634256631.\n",
      "[I 2024-10-15 11:53:51,168] Trial 12 finished with value: 0.95310882521546 and parameters: {'eta': 0.007993439563908246, 'alpha': 0.013065321426290254, 'num_leaves': 40, 'learning_rate': 0.0031853649000649353, 'max_depth': 13, 'n_estimators': 500, 'weights': 28.897282445278375}. Best is trial 12 with value: 0.95310882521546.\n",
      "[I 2024-10-15 11:53:53,746] Trial 13 finished with value: 0.9509410599674494 and parameters: {'eta': 0.02297947442896169, 'alpha': 0.009701488629671315, 'num_leaves': 20, 'learning_rate': 0.007203408155860705, 'max_depth': 13, 'n_estimators': 50, 'weights': 25.64442397113859}. Best is trial 12 with value: 0.95310882521546.\n",
      "[I 2024-10-15 11:53:56,313] Trial 14 finished with value: 0.9524263806771478 and parameters: {'eta': 0.05592290338998104, 'alpha': 0.001036112345498582, 'num_leaves': 30, 'learning_rate': 0.07872962646012988, 'max_depth': 13, 'n_estimators': 100, 'weights': 25.998461898780754}. Best is trial 12 with value: 0.95310882521546.\n",
      "[I 2024-10-15 11:53:58,869] Trial 15 finished with value: 0.9533759620825089 and parameters: {'eta': 0.0026014712711172356, 'alpha': 1.0746634886664752, 'num_leaves': 10, 'learning_rate': 0.005274127863988773, 'max_depth': 9, 'n_estimators': 10, 'weights': 3.048084022073473}. Best is trial 15 with value: 0.9533759620825089.\n",
      "[I 2024-10-15 11:54:01,359] Trial 16 finished with value: 0.9524780043938392 and parameters: {'eta': 0.004594704002269927, 'alpha': 0.11199621104837933, 'num_leaves': 10, 'learning_rate': 0.003709169641540574, 'max_depth': 9, 'n_estimators': 10, 'weights': 0.7923415624461185}. Best is trial 15 with value: 0.9533759620825089.\n",
      "[I 2024-10-15 11:54:03,938] Trial 17 finished with value: 0.9533150556145434 and parameters: {'eta': 0.055807796036491504, 'alpha': 1.393019771376304, 'num_leaves': 10, 'learning_rate': 0.030721157287252016, 'max_depth': 9, 'n_estimators': 10, 'weights': 58.205204263923356}. Best is trial 15 with value: 0.9533759620825089.\n",
      "[I 2024-10-15 11:54:06,461] Trial 18 finished with value: 0.9520347061033222 and parameters: {'eta': 0.07687697242422241, 'alpha': 1.9408853959949173, 'num_leaves': 10, 'learning_rate': 0.03739758416751495, 'max_depth': 9, 'n_estimators': 10, 'weights': 58.98353896542487}. Best is trial 15 with value: 0.9533759620825089.\n",
      "[I 2024-10-15 11:54:09,038] Trial 19 finished with value: 0.9525383718161524 and parameters: {'eta': 0.11825036668894366, 'alpha': 1.6612300237586877, 'num_leaves': 10, 'learning_rate': 0.03583341960958146, 'max_depth': 9, 'n_estimators': 10, 'weights': 81.17149623108973}. Best is trial 15 with value: 0.9533759620825089.\n",
      "[I 2024-10-15 11:54:11,537] Trial 20 finished with value: 0.9526280787962952 and parameters: {'eta': 0.028834034564173702, 'alpha': 0.28952208809887703, 'num_leaves': 10, 'learning_rate': 0.14575688156492714, 'max_depth': 9, 'n_estimators': 10, 'weights': 62.59089212536298}. Best is trial 15 with value: 0.9533759620825089.\n",
      "[I 2024-10-15 11:54:14,119] Trial 21 finished with value: 0.9535392898780198 and parameters: {'eta': 0.0037786432447169333, 'alpha': 0.11014863335055868, 'num_leaves': 50, 'learning_rate': 0.002162791008350987, 'max_depth': 11, 'n_estimators': 1000, 'weights': 32.22926235754661}. Best is trial 21 with value: 0.9535392898780198.\n",
      "[I 2024-10-15 11:54:16,669] Trial 22 finished with value: 0.953016230438166 and parameters: {'eta': 0.003352613376958918, 'alpha': 0.1045368768208392, 'num_leaves': 50, 'learning_rate': 0.020694316372434504, 'max_depth': 11, 'n_estimators': 1000, 'weights': 34.576188002965445}. Best is trial 21 with value: 0.9535392898780198.\n",
      "[I 2024-10-15 11:54:19,214] Trial 23 finished with value: 0.9525369184582685 and parameters: {'eta': 0.01710774452694204, 'alpha': 3.6634780066948474, 'num_leaves': 50, 'learning_rate': 0.0029848185869675867, 'max_depth': 11, 'n_estimators': 1000, 'weights': 48.753465885593684}. Best is trial 21 with value: 0.9535392898780198.\n",
      "[I 2024-10-15 11:54:21,782] Trial 24 finished with value: 0.9516735471449673 and parameters: {'eta': 0.0041628909102590945, 'alpha': 0.6554579106799504, 'num_leaves': 100, 'learning_rate': 0.017836109604166758, 'max_depth': 11, 'n_estimators': 1000, 'weights': 67.81261682263882}. Best is trial 21 with value: 0.9535392898780198.\n",
      "[I 2024-10-15 11:54:24,307] Trial 25 finished with value: 0.9527362789020192 and parameters: {'eta': 0.15545115251038405, 'alpha': 0.16032460972615414, 'num_leaves': 50, 'learning_rate': 0.0050075077657696435, 'max_depth': 9, 'n_estimators': 10, 'weights': 3.3060408897855935}. Best is trial 21 with value: 0.9535392898780198.\n",
      "[I 2024-10-15 11:54:26,840] Trial 26 finished with value: 0.9524410329139691 and parameters: {'eta': 0.051871256331209, 'alpha': 0.059852986714669536, 'num_leaves': 10, 'learning_rate': 0.0019259617110302788, 'max_depth': 9, 'n_estimators': 10, 'weights': 85.31230749019355}. Best is trial 21 with value: 0.9535392898780198.\n",
      "[I 2024-10-15 11:54:29,368] Trial 27 finished with value: 0.9522349123290293 and parameters: {'eta': 0.0019267005082566106, 'alpha': 1.3679928478704624, 'num_leaves': 10, 'learning_rate': 0.015687210287042435, 'max_depth': 11, 'n_estimators': 1000, 'weights': 54.26951012327196}. Best is trial 21 with value: 0.9535392898780198.\n",
      "[I 2024-10-15 11:54:32,371] Trial 28 finished with value: 0.9523472700446434 and parameters: {'eta': 0.000227338045288426, 'alpha': 0.3383939532033305, 'num_leaves': 50, 'learning_rate': 0.17496255242602032, 'max_depth': 9, 'n_estimators': 10, 'weights': 19.120876968520307}. Best is trial 21 with value: 0.9535392898780198.\n",
      "[I 2024-10-15 11:54:35,335] Trial 29 finished with value: 0.9521520620763377 and parameters: {'eta': 0.00530369427870289, 'alpha': 6.991440820825009, 'num_leaves': 10, 'learning_rate': 0.03598179694824538, 'max_depth': 11, 'n_estimators': 1000, 'weights': 71.67019422722153}. Best is trial 21 with value: 0.9535392898780198.\n"
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "def objective_2(trial):\n",
    "\n",
    "    xgboost_params = {\n",
    "        \"objective\" : \"binary:logistic\",\n",
    "        \"eval_metric\" : \"auc\",\n",
    "        \"device\" : \"cuda\",\n",
    "        \"eta\" : trial.suggest_loguniform(\"eta\", 1e-4, 1 ),\n",
    "        \"alpha\" : trial.suggest_loguniform(\"alpha\", 1e-3, 10),\n",
    "        \"num_leaves\" : trial.suggest_categorical(\"num_leaves\", [10,20,30,40,50,70, 100]),\n",
    "        \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-4, 1),\n",
    "        \"max_depth\" : trial.suggest_categorical(\"max_depth\", [5,7,9,11,13]),\n",
    "        \"n_estimators\" : trial.suggest_categorical(\"n_estimators\" , [10, 20, 50, 100, 500, 1000]),\n",
    "        \"weights\" : trial.suggest_uniform(\"weights\", 0, 100)\n",
    "    }\n",
    "    model = xgb.XGBClassifier()\n",
    "    auc = train_and_test_model(train_data, model, print = False, model_paramaters= xgboost_params)\n",
    "    return auc\n",
    "\n",
    "study2 = optuna.create_study(direction=\"maximize\")\n",
    "study2.optimize(objective_2, n_trials = 30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "study2.best_value\n",
    "\n",
    "\n",
    "best_model = xgb.XGBClassifier(**study2.best_params)\n",
    "best_model.fit(X = train_data.drop(\"loan_status\", axis = 1), y = train_data[\"loan_status\"])\n",
    "test_predictions = best_model.predict_proba(test_data.drop(\"id\", axis = 1))[:, 1]\n",
    "test_predictions_df = pd.DataFrame({\"id\": test_data[\"id\"], \"loan_status\" : test_predictions})\n",
    "test_predictions_df.to_csv(\"../Data/sample_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOLY SMOKES!!! - Adding weights increased test score to 0.94227 a big jump of 0.01!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-15 12:08:07,072] A new study created in memory with name: no-name-37ab9c27-ba23-4960-b92f-81084cad7650\n",
      "[I 2024-10-15 12:08:10,672] Trial 0 finished with value: 0.9516286720388608 and parameters: {'eta': 0.007676713687949517, 'alpha': 0.018971192741137115, 'num_leaves': 50, 'learning_rate': 0.0002712515480180054, 'max_depth': 27.645601380919704, 'n_estimators': 1000, 'weights': 24.337160833883043, 'colsample_bytree': 0.0268140109201112, 'scale_pos_weight': 0.04670977514623896, 'lambda': 0.004151514560678005}. Best is trial 0 with value: 0.9516286720388608.\n",
      "[I 2024-10-15 12:08:13,670] Trial 1 finished with value: 0.9531538575908544 and parameters: {'eta': 0.023038533251847015, 'alpha': 0.36512212524242865, 'num_leaves': 85, 'learning_rate': 0.0029813400105230792, 'max_depth': 11.862879835210059, 'n_estimators': 1000, 'weights': 371.5947515340989, 'colsample_bytree': 0.507303729175897, 'scale_pos_weight': 0.032902059887331706, 'lambda': 0.000174689915234299}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:16,574] Trial 2 finished with value: 0.9518211967947838 and parameters: {'eta': 0.4220593311102876, 'alpha': 0.27304946127330404, 'num_leaves': 70, 'learning_rate': 0.38890347415396465, 'max_depth': 17.156859230451985, 'n_estimators': 500, 'weights': 699.6480311901976, 'colsample_bytree': 0.05450628275426754, 'scale_pos_weight': 0.4707894850784722, 'lambda': 0.0016368624438164662}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:19,438] Trial 3 finished with value: 0.9523446190119002 and parameters: {'eta': 0.07127812810946692, 'alpha': 0.9289359508764282, 'num_leaves': 85, 'learning_rate': 0.0019285509803377066, 'max_depth': 11.009979727866748, 'n_estimators': 1000, 'weights': 148.23181427632258, 'colsample_bytree': 0.05601161420505554, 'scale_pos_weight': 0.0771341383754836, 'lambda': 0.6169404881630008}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:21,958] Trial 4 finished with value: 0.9527057622284127 and parameters: {'eta': 0.00025488860477290964, 'alpha': 0.12625910202599275, 'num_leaves': 100, 'learning_rate': 0.003422080229612191, 'max_depth': 27.37613282363854, 'n_estimators': 500, 'weights': 569.5836211917335, 'colsample_bytree': 0.0005432326702509532, 'scale_pos_weight': 0.7566837242523208, 'lambda': 0.01689475282376842}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:24,821] Trial 5 finished with value: 0.952619612213377 and parameters: {'eta': 0.00858220111921566, 'alpha': 0.1587577794871237, 'num_leaves': 70, 'learning_rate': 0.4149504238256485, 'max_depth': 16.653620389178613, 'n_estimators': 500, 'weights': 217.1743752456643, 'colsample_bytree': 0.00014562637462796048, 'scale_pos_weight': 0.8793368779740465, 'lambda': 0.6620683953198019}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:27,924] Trial 6 finished with value: 0.9526771247756807 and parameters: {'eta': 0.023135761459981842, 'alpha': 0.002598194482459354, 'num_leaves': 100, 'learning_rate': 0.00018298959128522913, 'max_depth': 15.453039260040306, 'n_estimators': 500, 'weights': 517.272017179183, 'colsample_bytree': 0.000208633594258648, 'scale_pos_weight': 0.8045154281802182, 'lambda': 0.004984140999818556}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:30,869] Trial 7 finished with value: 0.9526850502108781 and parameters: {'eta': 0.0015236214249898098, 'alpha': 1.5968657379129718, 'num_leaves': 50, 'learning_rate': 0.0018906427882974808, 'max_depth': 20.691269434611716, 'n_estimators': 500, 'weights': 405.47281875227867, 'colsample_bytree': 0.0002445821322631312, 'scale_pos_weight': 0.0094555234433042, 'lambda': 0.17882808117629026}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:33,702] Trial 8 finished with value: 0.9525715006010934 and parameters: {'eta': 0.03379270516007919, 'alpha': 0.003940313650172378, 'num_leaves': 70, 'learning_rate': 0.0003020573720906523, 'max_depth': 24.98060408245428, 'n_estimators': 1000, 'weights': 157.3328058472484, 'colsample_bytree': 0.0003086582279829441, 'scale_pos_weight': 0.3866010868457582, 'lambda': 0.8682471966069785}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:36,396] Trial 9 finished with value: 0.9519513993230045 and parameters: {'eta': 0.0016547082437911554, 'alpha': 3.389919771161009, 'num_leaves': 50, 'learning_rate': 0.44651180784898725, 'max_depth': 17.881083739297996, 'n_estimators': 500, 'weights': 143.72844288777586, 'colsample_bytree': 0.0008409010219243463, 'scale_pos_weight': 0.17991117884366742, 'lambda': 0.0006768895063003601}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:39,074] Trial 10 finished with value: 0.9526052175154607 and parameters: {'eta': 0.9308244819474274, 'alpha': 8.124578687505052, 'num_leaves': 85, 'learning_rate': 0.021093237214606677, 'max_depth': 10.62336751617186, 'n_estimators': 1000, 'weights': 927.856649447121, 'colsample_bytree': 0.817557103250948, 'scale_pos_weight': 0.2769910446438053, 'lambda': 0.00010034068891435156}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:42,223] Trial 11 finished with value: 0.9518017607233885 and parameters: {'eta': 0.00010065080267335009, 'alpha': 0.03635280051566707, 'num_leaves': 100, 'learning_rate': 0.011789582088527364, 'max_depth': 22.370198630499367, 'n_estimators': 1000, 'weights': 534.3454382869245, 'colsample_bytree': 0.0029002752424331616, 'scale_pos_weight': 0.6565770211752631, 'lambda': 0.04272630347573607}. Best is trial 1 with value: 0.9531538575908544.\n",
      "[I 2024-10-15 12:08:44,987] Trial 12 finished with value: 0.9532209666428967 and parameters: {'eta': 0.00015462132863571177, 'alpha': 0.27085268513579985, 'num_leaves': 85, 'learning_rate': 0.0016674496036688544, 'max_depth': 29.601281495711927, 'n_estimators': 500, 'weights': 687.2913440398372, 'colsample_bytree': 0.9891045103891548, 'scale_pos_weight': 0.6303938772482629, 'lambda': 0.024444964401024904}. Best is trial 12 with value: 0.9532209666428967.\n",
      "[I 2024-10-15 12:08:47,680] Trial 13 finished with value: 0.9525194768167274 and parameters: {'eta': 0.0012932108118469986, 'alpha': 0.6076596882937711, 'num_leaves': 85, 'learning_rate': 0.03728541624070164, 'max_depth': 29.69872721186767, 'n_estimators': 1000, 'weights': 788.3070940960376, 'colsample_bytree': 0.9220457240900768, 'scale_pos_weight': 0.5996191099919421, 'lambda': 0.0001401841026380207}. Best is trial 12 with value: 0.9532209666428967.\n",
      "[I 2024-10-15 12:08:50,744] Trial 14 finished with value: 0.9521723591720539 and parameters: {'eta': 0.09071291382631037, 'alpha': 0.028059484338314043, 'num_leaves': 85, 'learning_rate': 0.0009054767077785164, 'max_depth': 13.518550453820069, 'n_estimators': 500, 'weights': 361.74624793398584, 'colsample_bytree': 0.22923520042252948, 'scale_pos_weight': 0.9734221155558861, 'lambda': 0.05017406107967674}. Best is trial 12 with value: 0.9532209666428967.\n",
      "[I 2024-10-15 12:08:54,341] Trial 15 finished with value: 0.9529508707308825 and parameters: {'eta': 0.0004849071428629028, 'alpha': 0.508003660801524, 'num_leaves': 85, 'learning_rate': 0.0758681181742494, 'max_depth': 22.99473466775471, 'n_estimators': 1000, 'weights': 721.1513274703077, 'colsample_bytree': 0.2846605514001429, 'scale_pos_weight': 0.3648738352147814, 'lambda': 0.0004560268121988518}. Best is trial 12 with value: 0.9532209666428967.\n",
      "[I 2024-10-15 12:08:57,226] Trial 16 finished with value: 0.9523448444966267 and parameters: {'eta': 0.0047671682804498, 'alpha': 0.06010148244352888, 'num_leaves': 85, 'learning_rate': 0.00527059283527085, 'max_depth': 13.708480304291797, 'n_estimators': 500, 'weights': 982.0707181036246, 'colsample_bytree': 0.20973618426175628, 'scale_pos_weight': 0.5588130073955098, 'lambda': 0.01358277945221826}. Best is trial 12 with value: 0.9532209666428967.\n",
      "[I 2024-10-15 12:09:00,128] Trial 17 finished with value: 0.9525746756430706 and parameters: {'eta': 0.15990121699529808, 'alpha': 0.011259072126353489, 'num_leaves': 85, 'learning_rate': 0.0007360725268387398, 'max_depth': 19.883834168096108, 'n_estimators': 1000, 'weights': 361.39595190378304, 'colsample_bytree': 0.016639578137978596, 'scale_pos_weight': 0.20627398938171837, 'lambda': 0.06766760257398717}. Best is trial 12 with value: 0.9532209666428967.\n",
      "[I 2024-10-15 12:09:02,639] Trial 18 finished with value: 0.9521622446691843 and parameters: {'eta': 0.021255739471527597, 'alpha': 1.8521451256368249, 'num_leaves': 85, 'learning_rate': 0.00010771144838054087, 'max_depth': 24.79319646912686, 'n_estimators': 1000, 'weights': 677.0081444145594, 'colsample_bytree': 0.09968893265187996, 'scale_pos_weight': 0.6662530759938432, 'lambda': 0.0013177196489074386}. Best is trial 12 with value: 0.9532209666428967.\n",
      "[I 2024-10-15 12:09:05,151] Trial 19 finished with value: 0.9522668129046717 and parameters: {'eta': 0.003928862283054472, 'alpha': 0.2720236331758325, 'num_leaves': 85, 'learning_rate': 0.10707257866521494, 'max_depth': 19.279950670148033, 'n_estimators': 500, 'weights': 433.4898484742398, 'colsample_bytree': 0.0051137982065809695, 'scale_pos_weight': 0.48572835510932344, 'lambda': 0.18217272023344205}. Best is trial 12 with value: 0.9532209666428967.\n",
      "[I 2024-10-15 12:09:07,857] Trial 20 finished with value: 0.9533807673141522 and parameters: {'eta': 0.0004802982130366386, 'alpha': 0.007489270858433461, 'num_leaves': 85, 'learning_rate': 0.006688109406485953, 'max_depth': 29.806487149765996, 'n_estimators': 1000, 'weights': 839.3558780707012, 'colsample_bytree': 0.4617976471815494, 'scale_pos_weight': 0.4018544185835934, 'lambda': 0.005566006951340438}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:10,680] Trial 21 finished with value: 0.9530852306251723 and parameters: {'eta': 0.00010731155968832532, 'alpha': 0.001194833957068874, 'num_leaves': 85, 'learning_rate': 0.006713214568122481, 'max_depth': 29.390443830830996, 'n_estimators': 1000, 'weights': 840.9870295195831, 'colsample_bytree': 0.44343992222066697, 'scale_pos_weight': 0.3730457159164502, 'lambda': 0.0032540287118300753}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:13,468] Trial 22 finished with value: 0.9525754312230879 and parameters: {'eta': 0.00034772761294048877, 'alpha': 0.008959222310009507, 'num_leaves': 85, 'learning_rate': 0.0008188281192171246, 'max_depth': 26.467183968712526, 'n_estimators': 1000, 'weights': 612.1665673763713, 'colsample_bytree': 0.10843269823726513, 'scale_pos_weight': 0.2642295724073924, 'lambda': 0.021587177492197653}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:15,965] Trial 23 finished with value: 0.9525646859055446 and parameters: {'eta': 0.0008414958318177044, 'alpha': 0.06672351439617794, 'num_leaves': 85, 'learning_rate': 0.014457214197078391, 'max_depth': 28.713450739807413, 'n_estimators': 1000, 'weights': 844.8345377510661, 'colsample_bytree': 0.4902047572398603, 'scale_pos_weight': 0.1356434750367495, 'lambda': 0.007339793263676338}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:18,441] Trial 24 finished with value: 0.9523937709374343 and parameters: {'eta': 0.0002351400739363146, 'alpha': 0.28761509552574144, 'num_leaves': 85, 'learning_rate': 0.0030067938906088803, 'max_depth': 25.572259325455423, 'n_estimators': 1000, 'weights': 643.8717175819191, 'colsample_bytree': 0.9612167774497521, 'scale_pos_weight': 0.7750502824671034, 'lambda': 0.0003413052376052508}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:20,924] Trial 25 finished with value: 0.9529761428547225 and parameters: {'eta': 0.003513150706853999, 'alpha': 0.09436120967103967, 'num_leaves': 85, 'learning_rate': 0.001540985281598591, 'max_depth': 23.096795334508904, 'n_estimators': 1000, 'weights': 286.63768991453315, 'colsample_bytree': 0.10618810201275623, 'scale_pos_weight': 0.42813886876399465, 'lambda': 0.002034983517263315}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:23,383] Trial 26 finished with value: 0.9512257386793743 and parameters: {'eta': 0.0006811286118229805, 'alpha': 0.006823076043283432, 'num_leaves': 50, 'learning_rate': 0.006830915077108979, 'max_depth': 12.590259859774234, 'n_estimators': 500, 'weights': 807.8181407059518, 'colsample_bytree': 0.4968090607014617, 'scale_pos_weight': 0.5424497595220857, 'lambda': 0.00021483583903846902}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:25,944] Trial 27 finished with value: 0.9519320037495694 and parameters: {'eta': 0.000181134993580659, 'alpha': 0.633350440419137, 'num_leaves': 70, 'learning_rate': 0.0006277820749871052, 'max_depth': 27.98698048645823, 'n_estimators': 1000, 'weights': 751.8604360602163, 'colsample_bytree': 0.1666500685265634, 'scale_pos_weight': 0.6729807901452929, 'lambda': 0.0008749318210000818}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:28,409] Trial 28 finished with value: 0.9529994334806908 and parameters: {'eta': 0.01509123151106426, 'alpha': 0.0014368072488595434, 'num_leaves': 100, 'learning_rate': 0.03233058878532261, 'max_depth': 26.29602653288123, 'n_estimators': 500, 'weights': 461.9651415362732, 'colsample_bytree': 0.044803118352711085, 'scale_pos_weight': 0.2970940987191101, 'lambda': 0.0900254773136715}. Best is trial 20 with value: 0.9533807673141522.\n",
      "[I 2024-10-15 12:09:30,934] Trial 29 finished with value: 0.953461663090495 and parameters: {'eta': 0.047140792786446506, 'alpha': 0.01711874208067619, 'num_leaves': 50, 'learning_rate': 0.003437104423940365, 'max_depth': 21.34293461300789, 'n_estimators': 1000, 'weights': 871.6956737058179, 'colsample_bytree': 0.021799182649293196, 'scale_pos_weight': 0.8884918500730932, 'lambda': 0.03021278613410455}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:33,410] Trial 30 finished with value: 0.9525963959338807 and parameters: {'eta': 0.22293069915734953, 'alpha': 0.02169556294216116, 'num_leaves': 50, 'learning_rate': 0.000323550824766671, 'max_depth': 29.897797116067487, 'n_estimators': 1000, 'weights': 924.66520673042, 'colsample_bytree': 0.008610831815710538, 'scale_pos_weight': 0.9907753618962342, 'lambda': 0.02763731820441363}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:35,997] Trial 31 finished with value: 0.9528189868602939 and parameters: {'eta': 0.03675744581851965, 'alpha': 0.013081391796688104, 'num_leaves': 50, 'learning_rate': 0.003632878723409696, 'max_depth': 21.396378389554233, 'n_estimators': 1000, 'weights': 931.3878209974039, 'colsample_bytree': 0.46455993567941783, 'scale_pos_weight': 0.8604778369435614, 'lambda': 0.007711741179037299}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:38,579] Trial 32 finished with value: 0.952192422097807 and parameters: {'eta': 0.05390812333700462, 'alpha': 0.004494024844218944, 'num_leaves': 50, 'learning_rate': 0.0013521009513279506, 'max_depth': 23.94150386853983, 'n_estimators': 1000, 'weights': 22.97372210778417, 'colsample_bytree': 0.02456224030915744, 'scale_pos_weight': 0.9160980486613184, 'lambda': 0.1416592379478808}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:41,054] Trial 33 finished with value: 0.9530027456637031 and parameters: {'eta': 0.011755136192075332, 'alpha': 0.04651609519874394, 'num_leaves': 50, 'learning_rate': 0.009375223586383324, 'max_depth': 27.533189564753457, 'n_estimators': 1000, 'weights': 869.5825604377541, 'colsample_bytree': 0.05501272296722255, 'scale_pos_weight': 0.07860368401973947, 'lambda': 0.37345516860159644}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:43,555] Trial 34 finished with value: 0.9525444201254419 and parameters: {'eta': 0.11661431139269057, 'alpha': 0.1938111713297305, 'num_leaves': 85, 'learning_rate': 0.0029067834290232263, 'max_depth': 18.280316656345693, 'n_estimators': 1000, 'weights': 735.0961893803731, 'colsample_bytree': 0.0027754456589749385, 'scale_pos_weight': 0.7080503749347494, 'lambda': 0.037563681553265754}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:46,016] Trial 35 finished with value: 0.9516529934359192 and parameters: {'eta': 0.29066320226409587, 'alpha': 0.020650089237183835, 'num_leaves': 70, 'learning_rate': 0.8664010204192014, 'max_depth': 15.781480372806953, 'n_estimators': 1000, 'weights': 605.2451021027558, 'colsample_bytree': 0.3187430184936046, 'scale_pos_weight': 0.8322155898535225, 'lambda': 0.013027073289946374}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:48,706] Trial 36 finished with value: 0.9528881914450595 and parameters: {'eta': 0.05857479127540487, 'alpha': 0.1207812724037611, 'num_leaves': 100, 'learning_rate': 0.0048127435519906, 'max_depth': 28.288906239933876, 'n_estimators': 500, 'weights': 990.1567489665464, 'colsample_bytree': 0.1307227285765714, 'scale_pos_weight': 0.5993206284956587, 'lambda': 0.004798136204556215}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:51,207] Trial 37 finished with value: 0.9522879977834728 and parameters: {'eta': 0.007068382985636674, 'alpha': 1.263055729210358, 'num_leaves': 50, 'learning_rate': 0.0004711619784543142, 'max_depth': 26.575011965489274, 'n_estimators': 500, 'weights': 674.7824083435046, 'colsample_bytree': 0.0013692929648097556, 'scale_pos_weight': 0.7550665148627307, 'lambda': 0.31340857194084365}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:53,703] Trial 38 finished with value: 0.9529823696220567 and parameters: {'eta': 0.00260123028324171, 'alpha': 0.002253673260288502, 'num_leaves': 85, 'learning_rate': 0.002602558450916396, 'max_depth': 21.52626025724422, 'n_estimators': 1000, 'weights': 772.9275895708006, 'colsample_bytree': 0.027067351905809823, 'scale_pos_weight': 0.0012699904826980468, 'lambda': 0.008323368857491176}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:56,192] Trial 39 finished with value: 0.9525940883833991 and parameters: {'eta': 0.0001884032957275168, 'alpha': 0.005323327085723333, 'num_leaves': 70, 'learning_rate': 0.0011926275964418112, 'max_depth': 11.964533331913449, 'n_estimators': 500, 'weights': 257.006859374497, 'colsample_bytree': 0.07520831844636183, 'scale_pos_weight': 0.9221129178421921, 'lambda': 0.002740174504344408}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:09:58,715] Trial 40 finished with value: 0.9520741918039406 and parameters: {'eta': 0.029827296489764385, 'alpha': 0.427667109994771, 'num_leaves': 50, 'learning_rate': 0.018953254210777374, 'max_depth': 15.054362876833471, 'n_estimators': 1000, 'weights': 871.9089079170716, 'colsample_bytree': 0.7098424559265715, 'scale_pos_weight': 0.42452765073940996, 'lambda': 0.022436987667922473}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:01,196] Trial 41 finished with value: 0.9523931406530117 and parameters: {'eta': 0.00010977160405449298, 'alpha': 0.0018380228697625401, 'num_leaves': 85, 'learning_rate': 0.0079821774064143, 'max_depth': 29.221923819208993, 'n_estimators': 1000, 'weights': 829.1034900325043, 'colsample_bytree': 0.4112801747899356, 'scale_pos_weight': 0.3497265404255599, 'lambda': 0.0046953693102623}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:03,756] Trial 42 finished with value: 0.9527936704557171 and parameters: {'eta': 0.0001347828766780394, 'alpha': 0.0012472586576965051, 'num_leaves': 85, 'learning_rate': 0.001926089172359643, 'max_depth': 28.740565198632815, 'n_estimators': 1000, 'weights': 901.6082670694404, 'colsample_bytree': 0.6551807857590883, 'scale_pos_weight': 0.4466281395270943, 'lambda': 0.0026356848449603106}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:06,205] Trial 43 finished with value: 0.9524355401189026 and parameters: {'eta': 0.00030478006470293604, 'alpha': 0.003729124334711008, 'num_leaves': 85, 'learning_rate': 0.005377530521282184, 'max_depth': 27.267058493810097, 'n_estimators': 1000, 'weights': 805.0240382403986, 'colsample_bytree': 0.33379822688226285, 'scale_pos_weight': 0.51371951875852, 'lambda': 0.0009735573839101548}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:08,715] Trial 44 finished with value: 0.952023986249688 and parameters: {'eta': 0.0005407621975253873, 'alpha': 0.0010707654101459049, 'num_leaves': 85, 'learning_rate': 0.004056499136797262, 'max_depth': 17.233466471174825, 'n_estimators': 1000, 'weights': 542.6560786034431, 'colsample_bytree': 0.1941629376933149, 'scale_pos_weight': 0.08962544492887795, 'lambda': 0.014676617785593656}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:11,296] Trial 45 finished with value: 0.9526399205130238 and parameters: {'eta': 0.00015737916212106036, 'alpha': 0.002913195989812985, 'num_leaves': 85, 'learning_rate': 0.0022556156256254983, 'max_depth': 29.779717908339567, 'n_estimators': 1000, 'weights': 491.151338868907, 'colsample_bytree': 0.6179888593463895, 'scale_pos_weight': 0.22160618116577502, 'lambda': 0.030291629872578857}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:14,195] Trial 46 finished with value: 0.9528799246864821 and parameters: {'eta': 0.00028761238568506784, 'alpha': 0.20975149897983525, 'num_leaves': 100, 'learning_rate': 0.012025857412118292, 'max_depth': 25.394171583629813, 'n_estimators': 500, 'weights': 708.3764462818526, 'colsample_bytree': 0.2766256975128806, 'scale_pos_weight': 0.3314729770106568, 'lambda': 0.002915012700393071}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:17,597] Trial 47 finished with value: 0.9517564505908822 and parameters: {'eta': 0.001145865847423176, 'alpha': 0.08838293877557696, 'num_leaves': 85, 'learning_rate': 0.035283204383985065, 'max_depth': 27.10006183785328, 'n_estimators': 1000, 'weights': 958.2253508838282, 'colsample_bytree': 0.00011576588549319458, 'scale_pos_weight': 0.39403912789079715, 'lambda': 0.0641953963674238}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:20,695] Trial 48 finished with value: 0.9522221291720223 and parameters: {'eta': 0.00040895970502046575, 'alpha': 0.015226354796319551, 'num_leaves': 85, 'learning_rate': 0.006363459611755287, 'max_depth': 18.94093828528687, 'n_estimators': 1000, 'weights': 89.0272113854349, 'colsample_bytree': 0.9090898019640299, 'scale_pos_weight': 0.6095143843815225, 'lambda': 0.010255369514429112}. Best is trial 29 with value: 0.953461663090495.\n",
      "[I 2024-10-15 12:10:23,446] Trial 49 finished with value: 0.9524906304093866 and parameters: {'eta': 0.015445982721787313, 'alpha': 0.9093512115026283, 'num_leaves': 70, 'learning_rate': 0.001220247494294054, 'max_depth': 29.08602262000472, 'n_estimators': 500, 'weights': 343.1233466372998, 'colsample_bytree': 0.16533786516240492, 'scale_pos_weight': 0.16180592076845618, 'lambda': 0.0004836892842227497}. Best is trial 29 with value: 0.953461663090495.\n"
     ]
    }
   ],
   "source": [
    "def objective_3(trial):\n",
    "\n",
    "    xgboost_params = {\n",
    "        \"objective\" : \"binary:logistic\",\n",
    "        \"eval_metric\" : \"auc\",\n",
    "        \"device\" : \"cuda\",\n",
    "        \"eta\" : trial.suggest_loguniform(\"eta\", 1e-4, 1 ),\n",
    "        \"alpha\" : trial.suggest_loguniform(\"alpha\", 1e-3, 10),\n",
    "        \"num_leaves\" : trial.suggest_categorical(\"num_leaves\", [50,70, 85, 100]),\n",
    "        \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-4, 1),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 10,30),\n",
    "        \"n_estimators\" : trial.suggest_categorical(\"n_estimators\" , [ 500, 1000]),\n",
    "        \"weights\" : trial.suggest_uniform(\"weights\", 0, 1000),\n",
    "        \"colsample_bytree\" : trial.suggest_loguniform(\"colsample_bytree\", 1e-4, 1),\n",
    "        \"scale_pos_weight\" : trial.suggest_uniform(\"scale_pos_weight\", 1e-4, 1),\n",
    "        \"lambda\" : trial.suggest_loguniform(\"lambda\", 1e-4, 1),\n",
    "        \"jobs\" : -1\n",
    "    }\n",
    "    model = xgb.XGBClassifier()\n",
    "    auc = train_and_test_model(train_data, model, print = False, model_paramaters= xgboost_params)\n",
    "    return auc\n",
    "\n",
    "study3 = optuna.create_study(direction=\"maximize\")\n",
    "study3.optimize(objective_3, n_trials = 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "Invalid Parameter format for max_depth expect int but value='21.34293461300789'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m study3\u001b[38;5;241m.\u001b[39mbest_value\n\u001b[0;32m      4\u001b[0m best_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstudy3\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloan_status\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloan_status\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict_proba(test_data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m))[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      7\u001b[0m test_predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloan_status\u001b[39m\u001b[38;5;124m\"\u001b[39m : test_predictions})\n",
      "File \u001b[1;32mc:\\Users\\jackg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jackg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jackg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2100\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2100\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jackg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: Invalid Parameter format for max_depth expect int but value='21.34293461300789'"
     ]
    }
   ],
   "source": [
    "study3.best_value\n",
    "\n",
    "\n",
    "best_model = xgb.XGBClassifier(**study3.best_params)\n",
    "best_model.fit(X = train_data.drop(\"loan_status\", axis = 1), y = train_data[\"loan_status\"])\n",
    "test_predictions = best_model.predict_proba(test_data.drop(\"id\", axis = 1))[:, 1]\n",
    "test_predictions_df = pd.DataFrame({\"id\": test_data[\"id\"], \"loan_status\" : test_predictions})\n",
    "test_predictions_df.to_csv(\"../Data/sample_submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
